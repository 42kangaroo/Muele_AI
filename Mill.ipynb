{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Projektarbeit MÃ¼hle"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "import PySimpleGUI as psGui\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import datetime as dt\n",
    "import sklearn.preprocessing as pre\n",
    "from typing import List\n",
    "import math\n",
    "import multiprocessing as mp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Class definitions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "\n",
    "class MillEnv(object):\n",
    "    def __init__(self):\n",
    "        self.isPlaying: int = 1\n",
    "        self.gamePhase: list = [0,0]\n",
    "        self.moveNeeded: int = 0\n",
    "        self.inHand: list = [9,9]\n",
    "        self.onBoard: list = [0,0]\n",
    "        self.checkerPositions: list = [[],[]]\n",
    "        self.selected: int = -1\n",
    "        self.board: np.ndarray = np.zeros(24)\n",
    "        self.winner = 0\n",
    "        self.columns: np.ndarray = np.array([[0,1,2], # for determining how many checkers from each player are in a row\n",
    "                        [3,4,5],\n",
    "                        [6,7,8],\n",
    "                        [9,10,11],\n",
    "                        [12,13,14],\n",
    "                        [15,16,17],\n",
    "                        [18,19,20],\n",
    "                        [21,22,23],\n",
    "                        [0,9,21],\n",
    "                        [3,10,18],\n",
    "                        [6,11,15],\n",
    "                        [1,4,7],\n",
    "                        [16,19,22],\n",
    "                        [8,12,17],\n",
    "                        [5,13,20],\n",
    "                        [2,14,23],\n",
    "                        ])\n",
    "        self.previusStates = np.array([np.zeros(24)])\n",
    "    def makeMove(self, move: int) -> (bool, int):\n",
    "        if self.winner == 0:\n",
    "            valid: bool = False\n",
    "            last_state: tuple = self.getSummary(self.isPlaying)\n",
    "            last_player: int = self.isPlaying\n",
    "            reward: int = 0\n",
    "            if self.moveNeeded == 0: # Set Checker on position\n",
    "                if self.board[move] == 0:\n",
    "                    self.board[move] = self.isPlaying\n",
    "                    self.checkerPositions[1 if self.isPlaying == 1 else 0].append(move)\n",
    "                    valid = True\n",
    "                    if self.gamePhase[1 if self.isPlaying == 1 else 0] == 2:\n",
    "                        self.board[self.selected] = 0\n",
    "                        self.moveNeeded = 1\n",
    "                        self.checkerPositions[1 if self.isPlaying == 1 else 0].remove(self.selected)\n",
    "                        if self.board in self.previusStates:\n",
    "                            self.winner = 2\n",
    "                            self.gamePhase = [3,3]\n",
    "                    else:\n",
    "                        self.inHand[1 if self.isPlaying == 1 else 0] -= 1\n",
    "                        self.onBoard[1 if self.isPlaying == 1 else 0] += 1\n",
    "                        if np.array(self.inHand).sum() == 0:\n",
    "                            self.gamePhase = [1,1]\n",
    "                            self.moveNeeded = 1\n",
    "                    self.isPlaying = -self.isPlaying\n",
    "            elif self.moveNeeded == 1: # choose checker to move\n",
    "                if move in self.getValidMoves():\n",
    "                    self.previusStates = np.append(self.previusStates, [copy.deepcopy(self.board)], axis=0)\n",
    "                    valid = True\n",
    "                    self.selected = move\n",
    "                    if self.gamePhase[1 if self.isPlaying == 1 else 0] == 2:\n",
    "                        self.moveNeeded = 0\n",
    "                    else:\n",
    "                        self.moveNeeded = 2\n",
    "            elif self.moveNeeded == 2: # move checker up, down, left or right\n",
    "                if self.getMoveFields(self.selected)[move] == 0:\n",
    "                    idxToMoveAxis: np.ndarray = np.where(self.getInRows(self.selected) == self.selected)\n",
    "                    idxToMove = list(zip(idxToMoveAxis[1], idxToMoveAxis[0]))\n",
    "                    order = idxToMove[0][1]\n",
    "                    valid = True\n",
    "                    self.board[self.selected] = 0\n",
    "                    last_state = self.getSummary(last_player)\n",
    "                    self.checkerPositions[1 if self.isPlaying == 1 else 0].remove(self.selected)\n",
    "                    if move == 0: # up\n",
    "                        self.board[self.getInRows(self.selected)[1][idxToMove[abs(order-1)][0]-1]] = self.isPlaying\n",
    "                        self.checkerPositions[1 if self.isPlaying == 1 else 0].append(self.getInRows(self.selected)[1][idxToMove[abs(order-1)][0]-1])\n",
    "                    if move == 1: # right\n",
    "                        self.board[self.getInRows(self.selected)[0][idxToMove[order][0]+1]] = self.isPlaying\n",
    "                        self.checkerPositions[1 if self.isPlaying == 1 else 0].append(self.getInRows(self.selected)[0][idxToMove[order][0]+1])\n",
    "                    if move == 2: # down\n",
    "                        self.board[self.getInRows(self.selected)[1][idxToMove[abs(order-1)][0]+1]] = self.isPlaying\n",
    "                        self.checkerPositions[1 if self.isPlaying == 1 else 0].append(self.getInRows(self.selected)[1][idxToMove[abs(order-1)][0]+1])\n",
    "                    if move == 3: # left\n",
    "                        self.board[self.getInRows(self.selected)[0][idxToMove[order][0]-1]] = self.isPlaying\n",
    "                        self.checkerPositions[1 if self.isPlaying == 1 else 0].append(self.getInRows(self.selected)[0][idxToMove[order][0]-1])\n",
    "                    self.selected = -1\n",
    "                    self.moveNeeded = 1\n",
    "                    self.isPlaying = -self.isPlaying\n",
    "                    if (self.board == self.previusStates).all(axis=1).any():\n",
    "                        self.winner = 2\n",
    "                        self.gamePhase = [3,3]\n",
    "            elif self.moveNeeded == 3: # delete opponent checker\n",
    "                reward = 1\n",
    "                threeInChosenRow: np.ndarray = abs(self.board[self.getInRows(move)].sum(axis=1)) == 3\n",
    "                if self.board[move] == -1 * self.isPlaying and ~threeInChosenRow.any():\n",
    "                    valid = True\n",
    "                    self.board[move] = 0\n",
    "                    self.checkerPositions[1 if self.isPlaying == -1 else 0].remove(move)\n",
    "                    self.onBoard[1 if self.isPlaying == -1 else 0] -= 1\n",
    "                    self.previusStates = np.array([np.zeros(24)])\n",
    "                    if self.gamePhase[1 if self.isPlaying == -1 else 0] == 0:\n",
    "                        self.moveNeeded = 0\n",
    "                    elif self.gamePhase[1 if self.isPlaying == -1 else 0] == 1:\n",
    "                        if self.onBoard[1 if self.isPlaying == -1 else 0] == 3:\n",
    "                            self.gamePhase[1 if self.isPlaying == -1 else 0] = 2\n",
    "                        self.moveNeeded = 1\n",
    "                    elif self.gamePhase[1 if self.isPlaying == -1 else 0] == 2:\n",
    "                        self.gamePhase = [3,3]\n",
    "                        self.winner = last_player\n",
    "                    self.isPlaying = -self.isPlaying\n",
    "            if last_state[0] < self.getSummary(last_player)[0]:\n",
    "                self.isPlaying = last_player\n",
    "                self.moveNeeded = 3\n",
    "                canDelete: bool = False\n",
    "                for pos in self.checkerPositions[1 if self.isPlaying == -1 else 0]:\n",
    "                    if ~(abs(self.board[self.getInRows(pos)].sum(axis=1)) == 3).any():\n",
    "                        canDelete = True\n",
    "                        break\n",
    "                if not canDelete:\n",
    "                    valid = True\n",
    "                    self.isPlaying = -self.isPlaying\n",
    "                    if self.gamePhase[1 if self.isPlaying == -1 else 0] == 0:\n",
    "                        self.moveNeeded = 0\n",
    "                    elif self.gamePhase[1 if self.isPlaying == -1 else 0] >= 1:\n",
    "                        self.moveNeeded = 1\n",
    "            if self.gamePhase[1 if last_player == -1 else 0] == 1:\n",
    "                finished = True\n",
    "                for pos in self.checkerPositions[1 if last_player == -1 else 0]:\n",
    "                    if ~(self.getMoveFields(pos).all()):\n",
    "                        finished = False\n",
    "                        break\n",
    "                if finished:\n",
    "                    self.winner = last_player\n",
    "                    self.gamePhase = [3,3]\n",
    "            return valid, reward\n",
    "        return False, 0\n",
    "    def isFinished(self):\n",
    "        return self.winner\n",
    "    def getBoard(self) -> np.ndarray:\n",
    "        return self.board\n",
    "    def getInRows(self, pos: int) -> np.ndarray:\n",
    "        arrayPos: np.ndarray = self.columns == pos\n",
    "        return self.columns[arrayPos.any(axis=1)]\n",
    "    def reset(self):\n",
    "        self.isPlaying: int = 1\n",
    "        self.gamePhase: list = [0,0]\n",
    "        self.moveNeeded: int = 0\n",
    "        self.inHand: list = [9,9]\n",
    "        self.onBoard: list = [0,0]\n",
    "        self.checkerPositions: list = [[],[]]\n",
    "        self.selected: int = -1\n",
    "        self.board: np.ndarray = np.zeros(24)\n",
    "        self.winner = 0\n",
    "    def getSummary(self, player: int) -> (int, int):\n",
    "        columnSums:np.ndarray = self.board[self.columns].sum(axis=1)\n",
    "        numThreePlayerOpponent = np.count_nonzero(columnSums == -3 * player)\n",
    "        numThreePlayerActual = np.count_nonzero(columnSums == 3 * player)\n",
    "        return numThreePlayerActual, numThreePlayerOpponent\n",
    "    def getMoveFields(self, pos: int) -> np.ndarray:\n",
    "        moveFields: np.ndarray = np.zeros(4)\n",
    "        chosenRows: np.ndarray = self.getInRows(pos)\n",
    "        idxAxis: np.ndarray = np.where(chosenRows == pos)\n",
    "        idx = list(zip(idxAxis[1], idxAxis[0]))\n",
    "        order = idx[0][1]\n",
    "        if idx[order][0] != 1:\n",
    "            if idx[order][0] == 0:\n",
    "                moveFields[3] = 2\n",
    "                moveFields[1] = self.board[chosenRows[0][1]]\n",
    "            elif idx[order][0] == 2:\n",
    "                moveFields[1] = 2\n",
    "                moveFields[3] = self.board[chosenRows[0][1]]\n",
    "        else:\n",
    "            moveFields[3] = self.board[chosenRows[0][0]]\n",
    "            moveFields[1] = self.board[chosenRows[0][2]]\n",
    "        if idx[abs(order-1)][0] != 1:\n",
    "            if idx[abs(order-1)][0] == 0:\n",
    "                moveFields[0] = 2\n",
    "                moveFields[2] = self.board[chosenRows[1][1]]\n",
    "            elif idx[abs(order-1)][0] == 2:\n",
    "                moveFields[2] = 2\n",
    "                moveFields[0] = self.board[chosenRows[1][1]]\n",
    "        else:\n",
    "            moveFields[0] = self.board[chosenRows[1][0]]\n",
    "            moveFields[2] = self.board[chosenRows[1][2]]\n",
    "        return moveFields\n",
    "    def getValidMoves(self) -> List[int]:\n",
    "        validList = []\n",
    "        if self.moveNeeded == 0:\n",
    "            validList = np.arange(24)\n",
    "            validList = validList[self.board.flat == 0]\n",
    "        elif self.moveNeeded == 1:\n",
    "            validList = [pos for pos in self.checkerPositions[1 if self.isPlaying == 1 else 0] if ~self.getMoveFields(pos).all() or self.gamePhase[1 if self.isPlaying == 1 else 0] == 2]\n",
    "        elif self.moveNeeded == 2:\n",
    "            moveFields = self.getMoveFields(self.selected)\n",
    "            validList = [move for move in np.arange(4) if moveFields[move] == 0]\n",
    "        elif self.moveNeeded == 3:\n",
    "            validList = [pos for pos in self.checkerPositions[1 if self.isPlaying == -1 else 0] if ~(abs(self.board[self.getInRows(pos)].sum(axis=1)) == 3).any()]\n",
    "        return validList\n",
    "    def getFullState(self):\n",
    "        return self.getBoard(), self.isPlaying, self.gamePhase, self.moveNeeded,self.inHand, self.onBoard, self.checkerPositions, self.selected, self.winner, self.previusStates\n",
    "    def setFullState(self, board, isPlaying, gamePhase, moveNeded, inHand, onboard, checkerPositions, selected, winner, previusStates):\n",
    "        self.isPlaying: int = isPlaying\n",
    "        self.gamePhase: list = copy.deepcopy(gamePhase)\n",
    "        self.moveNeeded: int = moveNeded\n",
    "        self.inHand: list = copy.deepcopy(inHand)\n",
    "        self.onBoard: list = copy.deepcopy(onboard)\n",
    "        self.checkerPositions: list = copy.deepcopy(checkerPositions)\n",
    "        self.selected: int = selected\n",
    "        self.board: np.ndarray = copy.deepcopy(board)\n",
    "        self.winner: int = winner\n",
    "        self.previusStates = copy.deepcopy(previusStates)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Agent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self):\n",
    "        self.encoder = pre.OneHotEncoder(sparse=False).fit(np.array([1,0,-1]).reshape(-1,1))\n",
    "    def processState(self, player, state, moveNeeded, selected= None):\n",
    "        state = state * player\n",
    "        state_OH = np.array(self.encoder.transform(state.reshape(-1,1)))\n",
    "        if moveNeeded == 2 and selected is not None:\n",
    "            state[selected] = 2\n",
    "            selectedArray = np.zeros(24)\n",
    "            selectedArray[selected] = 1\n",
    "            # TODO append selectedArray to state_OH\n",
    "            state_OH = np.append(state_OH, selectedArray.reshape(-1,1), axis=1)\n",
    "        return state_OH.flatten()\n",
    "        #return state\n",
    "    def getPos(self, state: np.ndarray, temp: float, validMoves: List[int],network:keras.Model=None) -> np.ndarray:\n",
    "        if network is None:\n",
    "            return np.random.choice(validMoves)\n",
    "        softmaxed_output = keras.backend.softmax(network(state.reshape(1,-1))/ temp)\n",
    "        action_value = np.random.choice(np.array(softmaxed_output[0]), p= np.array(softmaxed_output[0]))\n",
    "        pos: np.ndarray = np.argmax(softmaxed_output[0] == action_value)\n",
    "        return pos\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Graphics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class MillDisplayer(object):\n",
    "    def __init__(self, MillEnvironment: MillEnv = None):\n",
    "        psGui.theme(\"dark\")\n",
    "        self.millImage: str = \"MÃ¼hleBrett.png\"\n",
    "        self.blackCheckerImage: str  = \"Schwarz.png\"\n",
    "        self.whiteCheckerImage: str = \"Weiss.png\"\n",
    "        self.millEnv: MillEnv = MillEnv()\n",
    "        if MillEnvironment is not None :\n",
    "            self.millEnv = MillEnvironment\n",
    "        self.ImageIDArray = np.array([])\n",
    "        self.imageLocations = [(10,490), (225, 490), (440, 490),\n",
    "                                (75,415), (225, 415), (375, 415),\n",
    "                                (150,340), (225, 340), (310, 340),\n",
    "                                (10,265), (75, 265), (150, 265),\n",
    "                                (310,265), (375, 265), (440, 265),\n",
    "                                (150,190), (225, 190), (310, 190),\n",
    "                                (75,115), (225, 115), (375, 115),\n",
    "                                (10,55), (225, 55), (440, 55)]\n",
    "        self.graph = psGui.Graph(\n",
    "                        canvas_size=(500, 500),\n",
    "                        graph_bottom_left=(0, 0),\n",
    "                        graph_top_right=(500, 500),\n",
    "                        )\n",
    "        self.statusTextBox = psGui.Text(\"Player \"+self.getPlayerName(self.millEnv.isPlaying)+\" is playing\", size=(50, 1))\n",
    "        self.layout_ = [[psGui.Button(\"Player vs. Player\"),psGui.Button(\"Player vs. Agent\"),psGui.Button(\"Agent vs. Agent\")],\n",
    "                        [self.statusTextBox],\n",
    "                       [self.graph],\n",
    "                       [psGui.Button(\"Close\")]]\n",
    "        self.window  = psGui.Window(\"Mill AI\", layout=self.layout_, finalize=True)\n",
    "        self.window.finalize()\n",
    "        self.graph.DrawImage(filename=self.millImage, location=(0,500))\n",
    "        self.activateClick()\n",
    "        self.reloadEnv()\n",
    "    def windowsLoop(self):\n",
    "        while True:\n",
    "            event, values = self.window.read()\n",
    "            if event == psGui.WIN_CLOSED or event == 'Close': # if user closes window or clicks cancel\n",
    "                break\n",
    "            elif not event == \"\":\n",
    "                self.reset()\n",
    "        self.window.close()\n",
    "    def makeMove(self, pos: int) -> bool:\n",
    "        valid, reward = self.millEnv.makeMove(pos)\n",
    "        if valid:\n",
    "            self.reloadEnv()\n",
    "        return valid\n",
    "    def reloadEnv(self):\n",
    "        self.setStatus(\"Player \" + self.getPlayerName(self.millEnv.isPlaying) + \" is playing - move needed: \" + str(self.millEnv.moveNeeded))\n",
    "        for imageID in self.ImageIDArray:\n",
    "            self.graph.DeleteFigure(imageID)\n",
    "        np.delete(self.ImageIDArray, np.s_[:])\n",
    "        for case, location in zip(self.millEnv.getBoard(), self.imageLocations):\n",
    "            if case == 1:\n",
    "                self.ImageIDArray = np.append(self.ImageIDArray,self.graph.DrawImage(filename=self.blackCheckerImage, location=location))\n",
    "            elif case == -1:\n",
    "                self.ImageIDArray = np.append(self.ImageIDArray,self.graph.DrawImage(filename=self.whiteCheckerImage, location=location))\n",
    "        self.window.refresh()\n",
    "    def getClicked(self, event) -> int:\n",
    "        for index, location in enumerate(self.imageLocations):\n",
    "            x2, y2 = location\n",
    "            if self.isInArea(event.x, -event.y + 500, x2, y2, 50, 50):\n",
    "                return index\n",
    "        return -1\n",
    "    def setAfterClicked(self, event):\n",
    "        pos = self.getClicked(event)\n",
    "        if pos == -1:\n",
    "            return False\n",
    "        if self.millEnv.moveNeeded == 2:\n",
    "            dif = self.millEnv.selected - pos\n",
    "            if dif == 0:\n",
    "                return False\n",
    "            if dif == -1:\n",
    "                pos = 1\n",
    "            elif dif == 1:\n",
    "                pos = 3\n",
    "            elif dif < 0:\n",
    "                pos = 2\n",
    "            elif dif > 0:\n",
    "                pos = 0\n",
    "        return self.makeMove(pos)\n",
    "    def isInArea(self, posX1: int, posY1: int, posX2: int, posY2: int, width: int, height: int) -> bool:\n",
    "        if posX2 <= posX1 <= posX2 + width:\n",
    "            if posY2 >= posY1 >= posY2 - height:\n",
    "                return True\n",
    "        return False\n",
    "    def setStatus(self, status: str):\n",
    "        self.statusTextBox.Update(status)\n",
    "    def close(self):\n",
    "        self.window.close()\n",
    "    def activateClick(self):\n",
    "        self.graph.TKCanvas.bind(\"<Button-1>\",self.setAfterClicked)\n",
    "    def deactivateClick(self):\n",
    "        self.graph.TKCanvas.unbind(\"<Button-1>\")\n",
    "    def read(self, timout: bool=False):\n",
    "        return self.window.read(0 if timout else None)\n",
    "    def reset(self):\n",
    "        self.millEnv.reset()\n",
    "        self.reloadEnv()\n",
    "    def getPlayerName(self, player: int) -> str:\n",
    "        if player == 1:\n",
    "            return \"black\"\n",
    "        elif player == -1:\n",
    "            return \"white\"\n",
    "        else:\n",
    "            return \"not a player\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Moderated Graphics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class ModeratedGraphics(object):\n",
    "    def __init__(self, gamma=0.9, num_sims=250, max_depth=15):\n",
    "        self.max_depth = max_depth\n",
    "        self.num_sims = num_sims\n",
    "        self.gamma = gamma\n",
    "        self.env = MillEnv()\n",
    "        self.graphics = MillDisplayer(self.env)\n",
    "        self.graphics.reloadEnv()\n",
    "        self.root: State = State(self.env)\n",
    "        self.mcts = MonteCarloTreeSearch(self.root)\n",
    "    def agentPlay(self):\n",
    "        self.resetMonteCarlo()\n",
    "        self.graphics.deactivateClick()\n",
    "        finished = 0\n",
    "        while finished == 0:\n",
    "            self.graphics.reloadEnv()\n",
    "            pos = self.mcts.best_action(self.gamma,multiplikator=self.num_sims, max_depth=self.max_depth)\n",
    "            self.mcts.setNewRoot(State(self.env))\n",
    "            self.graphics.makeMove(pos)\n",
    "            event, values = self.graphics.read(True)\n",
    "            if self.eventHandler(event):\n",
    "                return\n",
    "            finished = self.env.isFinished()\n",
    "        self.graphics.reloadEnv()\n",
    "        if not finished == 2:\n",
    "            self.graphics.setStatus(\"player \" + self.graphics.getPlayerName(finished) +\" won\")\n",
    "        else:\n",
    "            self.graphics.setStatus(\"The game ended in a draw\")\n",
    "    def playersVSPlayer(self):\n",
    "        self.graphics.activateClick()\n",
    "        self.graphics.reset()\n",
    "        finished = 0\n",
    "        while finished == 0:\n",
    "            event, values = self.graphics.read()\n",
    "            if self.eventHandler(event):\n",
    "                return\n",
    "            self.graphics.reloadEnv()\n",
    "            finished = self.env.isFinished()\n",
    "        self.graphics.reloadEnv()\n",
    "        if not finished == 2:\n",
    "            self.graphics.setStatus(\"player \" + self.graphics.getPlayerName(finished) +\" won\")\n",
    "        else:\n",
    "            self.graphics.setStatus(\"The game ended in a draw\")\n",
    "        self.graphics.deactivateClick()\n",
    "    def playerVSAgent(self):\n",
    "        self.graphics.activateClick()\n",
    "        self.resetMonteCarlo()\n",
    "        finished = 0\n",
    "        while finished == 0:\n",
    "            event, values = self.graphics.read(True)\n",
    "            if self.eventHandler(event):\n",
    "                return\n",
    "            if self.env.isPlaying == 1:\n",
    "                self.graphics.activateClick()\n",
    "            else:\n",
    "                self.graphics.deactivateClick()\n",
    "                self.root = State(self.env)\n",
    "                self.mcts.setNewRoot(self.root)\n",
    "                pos = self.mcts.best_action(self.gamma,multiplikator=self.num_sims, max_depth=self.max_depth)\n",
    "                self.mcts.setNewRoot(State(self.env))\n",
    "                self.graphics.makeMove(pos)\n",
    "            self.graphics.reloadEnv()\n",
    "            finished = self.env.isFinished()\n",
    "        self.graphics.reloadEnv()\n",
    "        if not finished == 2:\n",
    "            self.graphics.setStatus(\"player \" + self.graphics.getPlayerName(finished) +\" won\")\n",
    "        else:\n",
    "            self.graphics.setStatus(\"The game ended in a draw\")\n",
    "        self.graphics.deactivateClick()\n",
    "    def playLoop(self):\n",
    "        self.graphics.deactivateClick()\n",
    "        self.playerVSAgent()\n",
    "        finished = False\n",
    "        while not finished:\n",
    "            event, values = self.graphics.read()\n",
    "            finished = self.eventHandler(event)\n",
    "    def eventHandler(self, event) -> bool:\n",
    "        if event == psGui.WIN_CLOSED or event == 'Close': # if user closes window or clicks cancel\n",
    "            self.graphics.close()\n",
    "            return True\n",
    "        elif event == \"Agent vs. Agent\":\n",
    "            self.agentPlay()\n",
    "        elif event == \"Player vs. Player\":\n",
    "            self.playersVSPlayer()\n",
    "        elif event == \"Player vs. Agent\":\n",
    "            self.playerVSAgent()\n",
    "        return False\n",
    "    def resetMonteCarlo(self):\n",
    "        self.env.reset()\n",
    "        self.root = State(self.env)\n",
    "        self.mcts.setNewRoot(self.root)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Memory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    def __init__(self, size: int):\n",
    "        self.size = size\n",
    "        self.curr_write_idx = 0\n",
    "        self.available_samples = 0\n",
    "        self.buffer = np.array([(np.zeros(24,dtype=np.float32), 0.0, 0.0, np.zeros(24,\n",
    "                                dtype=np.float32), False) for index in range(self.size)], dtype=object)\n",
    "        self.base_node, self.leaf_nodes = create_tree([0 for index in range(self.size)])\n",
    "        self.frame_idx = 0\n",
    "        self.action_idx = 1\n",
    "        self.reward_idx = 2\n",
    "        self.terminal_idx = 3\n",
    "        self.beta = 0.4\n",
    "        self.alpha = 0.6\n",
    "        self.min_priority = 0.01\n",
    "\n",
    "    def append(self, experience: tuple, priority: float):\n",
    "        self.buffer[self.curr_write_idx] = experience\n",
    "        self.update(self.curr_write_idx, priority)\n",
    "        self.curr_write_idx += 1\n",
    "        # reset the current writer position index if creater than the allowed size\n",
    "        if self.curr_write_idx >= self.size:\n",
    "            self.curr_write_idx = 0\n",
    "        # max out available samples at the memory buffer size\n",
    "        if self.available_samples + 1 < self.size:\n",
    "            self.available_samples += 1\n",
    "        else:\n",
    "            self.available_samples = self.size - 1\n",
    "\n",
    "    def update(self, idx: int, priority: float):\n",
    "        update(self.leaf_nodes[idx], self.adjust_priority(priority))\n",
    "\n",
    "    def adjust_priority(self, priority: float):\n",
    "        return np.power(priority + self.min_priority, self.alpha)\n",
    "\n",
    "    def sample(self, num_samples: int):\n",
    "        sampled_idxs = []\n",
    "        is_weights = []\n",
    "        sample_no = 0\n",
    "        while sample_no < num_samples:\n",
    "            sample_val = np.random.uniform(0, self.base_node.value)\n",
    "            samp_node = retrieve(sample_val, self.base_node)\n",
    "            if samp_node.idx < self.available_samples - 1:\n",
    "                sampled_idxs.append(samp_node.idx)\n",
    "                p = samp_node.value / self.base_node.value\n",
    "                is_weights.append((self.available_samples + 1) * p)\n",
    "                sample_no += 1\n",
    "        # apply the beta factor and normalise so that the maximum is_weight < 1\n",
    "        is_weights = np.array(is_weights)\n",
    "        is_weights = np.power(is_weights, -self.beta)\n",
    "        is_weights = is_weights / np.max(is_weights)\n",
    "        # now load up the state and next state variables according to sampled idxs\n",
    "        return self.buffer[sampled_idxs], sampled_idxs, is_weights\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "class Residual_Model(keras.Model):\n",
    "    def __init__(self, hidden_size: int, num_actions: int, input_shape: (int, int, int) = None, input_tensor: tf.Tensor = None):\n",
    "        super(Residual_Model, self).__init__()\n",
    "        self.residual = keras.applications.resnet_v2.ResNet50V2(include_top=False, weights=None, input_shape=input_shape, input_tensor=input_tensor, pooling='max')\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.dense1 = keras.layers.Dense(hidden_size *3, activation='relu',\n",
    "                                         kernel_initializer=keras.initializers.he_normal())\n",
    "        self.dense2 = keras.layers.Dense(hidden_size * 4, activation='relu',\n",
    "                                         kernel_initializer=keras.initializers.he_normal())\n",
    "        self.dense3 = keras.layers.Dense(hidden_size * 5, activation='relu',\n",
    "                                         kernel_initializer=keras.initializers.he_normal())\n",
    "        self.dense4 = keras.layers.Dense(hidden_size * 4, activation='relu',\n",
    "                                         kernel_initializer=keras.initializers.he_normal())\n",
    "        self.adv_dense1 = keras.layers.Dense(hidden_size * 3, activation='relu',\n",
    "                                         kernel_initializer=keras.initializers.he_normal())\n",
    "        self.adv_dense2 = keras.layers.Dense(hidden_size * 4, activation='relu',\n",
    "                                         kernel_initializer=keras.initializers.he_normal())\n",
    "        self.adv_dense3 = keras.layers.Dense(hidden_size * 3, activation='relu',\n",
    "                                         kernel_initializer=keras.initializers.he_normal())\n",
    "        self.adv_out = keras.layers.Dense(num_actions, activation='softmax',\n",
    "                                          kernel_initializer=keras.initializers.he_normal())\n",
    "        self.v_dense1 = keras.layers.Dense(hidden_size * 3, activation='relu',\n",
    "                                         kernel_initializer=keras.initializers.he_normal())\n",
    "        self.v_dense2 = keras.layers.Dense(hidden_size * 4, activation='relu',\n",
    "                                         kernel_initializer=keras.initializers.he_normal())\n",
    "        self.v_out = keras.layers.Dense(1, activation='sigmoid',kernel_initializer=keras.initializers.he_normal())\n",
    "\n",
    "    def call(self, input, **kwargs):\n",
    "        x = self.residual(input)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        adv = self.adv_dense1(x)\n",
    "        adv = self.adv_dense2(adv)\n",
    "        adv = self.adv_dense3(adv)\n",
    "        adv = self.adv_out(adv)\n",
    "        v = self.v_dense1(x)\n",
    "        v = self.v_dense2(v)\n",
    "        v = self.v_out(v)\n",
    "        return adv, v\n",
    "\n",
    "    @tf.function\n",
    "    def traceable(self, input, **kwargs):\n",
    "        return self(input, **kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### TreeNode"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, left, right, is_leaf: bool = False, idx = None):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.is_leaf = is_leaf\n",
    "        self.value = sum(n.value for n in (left, right) if n is not None)\n",
    "        self.parent = None\n",
    "        self.idx = idx  # this value is only set for leaf nodes\n",
    "        if left is not None:\n",
    "            left.parent = self\n",
    "        if right is not None:\n",
    "            right.parent = self\n",
    "\n",
    "    @classmethod\n",
    "    def create_leaf(cls, value, idx):\n",
    "        leaf = cls(None, None, is_leaf=True, idx=idx)\n",
    "        leaf.value = value\n",
    "        return leaf\n",
    "\n",
    "\n",
    "def create_tree(input: list):\n",
    "    nodes = [Node.create_leaf(v, i) for i, v in enumerate(input)]\n",
    "    leaf_nodes = nodes\n",
    "    while len(nodes) > 1:\n",
    "        inodes = iter(nodes)\n",
    "        nodes = [Node(*pair) for pair in zip(inodes, inodes)]\n",
    "\n",
    "    return nodes[0], leaf_nodes\n",
    "\n",
    "def retrieve(value: float, node: Node):\n",
    "    if node.is_leaf:\n",
    "        return node\n",
    "\n",
    "    if node.left.value >= value:\n",
    "        return retrieve(value, node.left)\n",
    "    else:\n",
    "        return retrieve(value - node.left.value, node.right)\n",
    "\n",
    "def update(node: Node, new_value: float):\n",
    "    change = new_value - node.value\n",
    "\n",
    "    node.value = new_value\n",
    "    propagate_changes(change, node.parent)\n",
    "\n",
    "\n",
    "def propagate_changes(change: float, node: Node):\n",
    "    node.value += change\n",
    "\n",
    "    if node.parent is not None:\n",
    "        propagate_changes(change, node.parent)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### State"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "class State(object):\n",
    "    def __init__(self, env: MillEnv, last_move = None, parent = None, seed = None):\n",
    "        self.last_move = last_move\n",
    "        self.n = 0\n",
    "        self.q = 0\n",
    "        self.terminal = env.isFinished()\n",
    "        self.valid_moves = env.getValidMoves()\n",
    "        self.untried_actions: list = list(self.valid_moves)\n",
    "        self.state = env.getFullState()\n",
    "        self.parent = parent\n",
    "        self.children = np.array([])\n",
    "        self.results = defaultdict(float)\n",
    "        self.env: MillEnv = env\n",
    "        self.move_value = 0\n",
    "        self.random_gen = np.random.Generator(np.random.PCG64(seed))\n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.untried_actions) == 0\n",
    "    def best_child(self, c_param=1.):\n",
    "        choices_weights = [\n",
    "            (c.q / c.n) + c_param * np.sqrt((2 * np.log(self.n) / c.n))\n",
    "            for c in self.children\n",
    "        ]\n",
    "        return self.children[np.argmax(choices_weights)]\n",
    "    def rollout_policy(self):\n",
    "        return self.valid_moves[np.random.randint(len(self.valid_moves))]\n",
    "    def is_terminal_node(self):\n",
    "        return self.terminal\n",
    "    def expand(self):\n",
    "        action = self.untried_actions.pop()\n",
    "        self.env.setFullState(self.state[0], self.state[1],self.state[2], self.state[3],self.state[4], self.state[5],self.state[6], self.state[7], self.state[8], self.state[9])\n",
    "        self.env.makeMove(action)\n",
    "        child_node = State(self.env,action, parent=self)\n",
    "        self.children = np.append(self.children, child_node)\n",
    "        return child_node\n",
    "    def rollout(self, discount, max_depth = 20, root = None):\n",
    "        if self.parent is not None:\n",
    "            self.env.setFullState(self.parent.state[0], self.parent.state[1],self.parent.state[2], self.parent.state[3],self.parent.state[4], self.parent.state[5],self.parent.state[6], self.parent.state[7], self.parent.state[8], self.parent.state[9])\n",
    "        else: \n",
    "            self.env.setFullState(self.state[0], self.state[1],self.state[2], self.state[3],self.state[4], self.state[5],self.state[6], self.state[7], self.state[8], self.state[9])\n",
    "        reward = defaultdict(float)\n",
    "        depth = max_depth - self.depth(root)\n",
    "        for iteration in range(depth):\n",
    "            last_player = self.env.isPlaying\n",
    "            if iteration == 0 and self.last_move:\n",
    "                action = self.last_move\n",
    "            else:\n",
    "                action = self.random_gen.choice(self.env.getValidMoves())\n",
    "            if iteration == 0:\n",
    "                self.move_value = self.env.makeMove(action)[1]\n",
    "            else:\n",
    "                reward[last_player] += self.env.makeMove(action)[1]\n",
    "            if self.env.isFinished() != 0:\n",
    "                depth = iteration\n",
    "                break\n",
    "        if self.parent:\n",
    "            if self.env.isFinished() == self.parent.state[1]:\n",
    "                reward[self.parent.state[1]] += discount**depth *5\n",
    "            elif self.env.isFinished() == -self.parent.state[1]:\n",
    "                reward[-self.parent.state[1]] += discount**depth *5\n",
    "            elif self.env.isFinished() == 2:\n",
    "                reward[self.parent.state[1]] -= 0.5\n",
    "        return reward\n",
    "    def depth(self, root):\n",
    "        depth = 0\n",
    "        current_parent = self\n",
    "        while current_parent.parent != root and current_parent.parent:\n",
    "            current_parent = current_parent.parent\n",
    "            depth += 1\n",
    "        return depth\n",
    "    def backpropagate(self, result):\n",
    "        current_node = self\n",
    "        iters = 1\n",
    "        while current_node.parent:\n",
    "            current_node.n += 1\n",
    "            result[current_node.parent.state[1]] += current_node.move_value/iters\n",
    "            current_node.q += result[current_node.parent.state[1]]\n",
    "            current_node.q -= result[-current_node.parent.state[1]]\n",
    "            current_node = current_node.parent\n",
    "            iters += 1\n",
    "        current_node.n +=1\n",
    "    def mergeChildren(self, states: np.ndarray):\n",
    "        self.q = np.sum([state.q for state in states])\n",
    "        self.n = np.sum([state.n for state in states])\n",
    "        childrenAll: np.ndarray = np.array([state.children for state in states], dtype= object).transpose()\n",
    "        for children in childrenAll:\n",
    "            valididx = ~(children == None)\n",
    "            if len(valididx) >= 1:\n",
    "                self.children = np.append(self.children, children[valididx].reshape(-1)[0].merge(children[valididx]))\n",
    "        return self\n",
    "    def merge(self, children):\n",
    "        self.q = np.sum([state.q for state in children])\n",
    "        self.n = np.sum([state.n for state in children])\n",
    "        return self\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Monte Carlo Tree Search"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "class MonteCarloTreeSearch(object):\n",
    "    def __init__(self, node):\n",
    "        self.root: State = node\n",
    "    def best_action(self, gamma, parallel = mp.cpu_count()//2, multiplikator = 250, max_depth = 20) -> int:\n",
    "        \"\"\"\n",
    "        get best action of state\n",
    "        Parameters\n",
    "        -------\n",
    "        :parameter gamma: the discount factor\n",
    "        :parameter max_depth: depth to search actions\n",
    "        :parameter multiplikator : number of simulations performed to get the best action\n",
    "        Returns\n",
    "        -------\n",
    "        :returns best child state\n",
    "        \"\"\"\n",
    "        if __name__ == '__main__':\n",
    "            with mp.Pool(parallel) as pool:\n",
    "                result = pool.starmap(self.train, [(gamma, multiplikator,max_depth) for _ in range(parallel)])\n",
    "        self.root.mergeChildren(np.array(result))\n",
    "        # to select best child go for exploitation only\n",
    "        self.root.env.setFullState(self.root.state[0],self.root.state[1],self.root.state[2],self.root.state[3],self.root.state[4],self.root.state[5],self.root.state[6],self.root.state[7],self.root.state[8], self.root.state[9])\n",
    "        return self.root.best_child(c_param=0.).last_move\n",
    "    def train(self, gamma, multiplikator = 500, max_depth = 20):\n",
    "        \"\"\"\n",
    "        get best action of state\n",
    "        Parameters\n",
    "        -------\n",
    "        :parameter gamma: the discount factor\n",
    "        :parameter max_depth: depth to search actions\n",
    "        :parameter multiplikator : number of simulations performed to get the best action\n",
    "        Returns\n",
    "        -------\n",
    "        :returns best child state\n",
    "        \"\"\"\n",
    "        self.root.random_gen = np.random.Generator(np.random.PCG64())\n",
    "        simulations_number = int(len(self.root.valid_moves)**1.2 * multiplikator)\n",
    "        for i in range(simulations_number):\n",
    "            v = self._tree_policy(max_depth)\n",
    "            reward = v.rollout(gamma, max_depth, self.root)\n",
    "            v.backpropagate(reward)\n",
    "        for child in self.root.children:\n",
    "            child.children = np.array([])\n",
    "        return self.root\n",
    "\n",
    "\n",
    "    def setNewRoot(self, node):\n",
    "        self.root = node\n",
    "    def _tree_policy(self, max_depth = 200, expl = 1.4):\n",
    "        \"\"\"\n",
    "        selects node to run rollout/playout for\n",
    "        Returns\n",
    "        -------\n",
    "        \"\"\"\n",
    "\n",
    "        current_node = self.root\n",
    "        itern  = 0\n",
    "        while not current_node.is_terminal_node() and itern < max_depth:\n",
    "            if not current_node.is_fully_expanded():\n",
    "                return current_node.expand()\n",
    "            else:\n",
    "                current_node = current_node.best_child(expl)\n",
    "            itern += 1\n",
    "        return current_node\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tests"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Environment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12 13 14]\n",
      " [ 2 14 23]]\n",
      "[ 5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "[ 1.  1.  1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n",
      "0\n",
      "False\n",
      "[ 1.  0.  0. -1.]\n",
      "(1, 0)\n"
     ]
    }
   ],
   "source": [
    "envis = MillEnv()\n",
    "print(envis.getInRows(14))\n",
    "\n",
    "envis.makeMove(0)\n",
    "envis.makeMove(3)\n",
    "envis.makeMove(2)\n",
    "envis.makeMove(4)\n",
    "envis.makeMove(1)\n",
    "envis.makeMove(3)\n",
    "envis.makeMove(3)\n",
    "print(envis.getValidMoves())\n",
    "print(envis.getBoard())\n",
    "print(envis.moveNeeded)\n",
    "ThreeInChosenRow = abs(envis.board[envis.getInRows(0)].sum(axis=1)) == 3\n",
    "print(~ThreeInChosenRow.any())\n",
    "print(envis.getMoveFields(4))\n",
    "print(envis.getSummary(1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Agent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96,)\n",
      "Gewonnen hat 2\n",
      "Gewonnen hat 2\n",
      "Gewonnen hat 2\n",
      "Gewonnen hat 2\n",
      "Gewonnen hat 2\n",
      "Gewonnen hat 2\n",
      "Gewonnen hat 2\n",
      "Gewonnen hat 2\n",
      "Gewonnen hat 2\n",
      "Gewonnen hat 2\n",
      "0.6103560924530029\n",
      "0.06104590892791748\n"
     ]
    }
   ],
   "source": [
    "envi = MillEnv()\n",
    "ag = Agent()\n",
    "print(ag.processState(1,envi.getBoard(), 2,3).shape)\n",
    "firstTime = time.time()\n",
    "iters = 10\n",
    "for i in range(iters):\n",
    "    envi.reset()\n",
    "    while envi.isFinished() == 0:\n",
    "        validNow = envi.makeMove(ag.getPos(envi.getBoard(), 0, envi.getValidMoves()))\n",
    "        if not validNow:\n",
    "            print(\"invalid\")\n",
    "    print(f\"Gewonnen hat {envi.isFinished()}\")\n",
    "print(time.time()- firstTime)\n",
    "print((time.time()-firstTime)/iters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### merge"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mcts = MonteCarloTreeSearch(State(MillEnv()))\n",
    "%time print(mcts.best_action(0.99, multiplikator=750, max_depth=12))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Displayer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "displayer = MillDisplayer()\n",
    "displayer.windowsLoop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Monte Carlo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MCGraphics = ModeratedGraphics(gamma=0.9, max_depth=12, num_sims=750)\n",
    "MCGraphics.playLoop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}